{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import IPython.core.display as di\n",
    "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_items0 = pd.read_csv(\"DATA/DMC_2017_task/items.csv\", sep = \"|\")\n",
    "del df_items0[\"campaignIndex\"]\n",
    "df_items0.pharmForm = df_items0.pharmForm.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def content(df):\n",
    "    content = pd.DataFrame(df.content.str.split('X',2).tolist(), columns = ['x','y','z'])\n",
    "    content = content.fillna('1')\n",
    "    content.x = pd.to_numeric(content.x, errors='coerce')\n",
    "    content.y = pd.to_numeric(content.y, errors='coerce')\n",
    "    content.z = pd.to_numeric(content.z, errors='coerce')\n",
    "    content['Content'] = content.x * content.y * content.z\n",
    "    df1 = pd.concat([df, content], axis=1, join_axes=[df.index])\n",
    "    df2 = df1.drop([\"x\", \"y\", \"z\", \"content\"], axis=1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_items1 = content(df_items0)\n",
    "df_items1.category = df_items1.category.fillna(value = df_items1.category.mean())\n",
    "df_items1.Content = df_items1.Content.fillna(value = df_items1.Content.mean())\n",
    "df_items1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def missing(df):\n",
    "    print('Size of testing dataset : %d' % (df.shape[0]))\n",
    "    df1 = df.dropna()\n",
    "    print('Size of testing dataset DropNA : %d' % (df1.shape[0]))\n",
    "    display(df.isnull().sum())\n",
    "    \n",
    "def onehot2(df):\n",
    "    df_oh = pd.DataFrame(np_utils.to_categorical(df,(max(df)+1)))\n",
    "    original_dim = df_oh.shape[1]\n",
    "    print('original dimension : %d' % df_oh.shape[1])\n",
    "    return df_oh, original_dim\n",
    "\n",
    "def pre_item(df):\n",
    "    #\n",
    "    df_num = df[column_conti]\n",
    "    sc = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "    Z = pd.DataFrame(sc.fit_transform(df_num))\n",
    "    Z.columns = column_conti\n",
    "    \n",
    "    df_cat = df.drop(column_conti, axis=1)\n",
    "    df_cat = df_cat.reset_index(drop=True, inplace=False, col_level=0, col_fill='')\n",
    "    \n",
    "    df1 = df_cat.join(Z, on=None, how='inner', lsuffix='', rsuffix='', sort=False)\n",
    "    \n",
    "    #\n",
    "    m1, m1.dim = onehot2(df.manufacturer)\n",
    "    s1, s1.dim = onehot2(df.salesIndex)\n",
    "    \n",
    "    df2 = pd.concat([df1, m1, s1], axis=1, join_axes=[df.index])\n",
    "    df3 = df2.drop([\"manufacturer\", \"salesIndex\"], axis=1)\n",
    "    df4 = pd.get_dummies(df3)\n",
    "    print(df4.shape)\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing(df_items1)\n",
    "column_conti = [\"category\", \"rrp\", \"Content\"]\n",
    "df_items2 = pre_item(df_items1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auto(df, dim):\n",
    "    from keras.layers import Input, Dense\n",
    "    from keras.models import Model\n",
    "    from keras.callbacks import TensorBoard\n",
    "    encoding_dim = dim\n",
    "\n",
    "    input_img = Input(shape=(df.shape[1],))\n",
    "    encoded = Dense(2000, activation='relu')(input_img)\n",
    "    encoded = Dense(1000, activation='relu')(encoded)\n",
    "    encoded = Dense(500, activation='relu')(encoded)\n",
    "    encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "    decoded = Dense(500, activation='relu')(encoded)\n",
    "    decoded = Dense(1000, activation='relu')(decoded)\n",
    "    decoded = Dense(2000, activation='relu')(decoded)\n",
    "    decoded = Dense(df.shape[1], activation='sigmoid')(decoded)\n",
    "\n",
    "    autoencoder = Model(input = input_img, output = decoded)\n",
    "    autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy')\n",
    "    history = autoencoder.fit(df, df,\n",
    "                              nb_epoch = nb_epoch,\n",
    "                              batch_size = 256,\n",
    "                              shuffle = True,\n",
    "                              validation_split = 0.2)\n",
    "    \n",
    "    from keras import backend as K\n",
    "    target_layer = K.function(autoencoder.inputs, [autoencoder.layers[4].output])\n",
    "    ## Extract output from the target hidden layer.\n",
    "    target_layer_out = target_layer([df])\n",
    "    df_auto = pd.DataFrame(np.array(target_layer_out[0]))\n",
    "    print('encoding dimension : %d' % (df_auto.shape[1]))\n",
    "    return df_auto, history\n",
    "\n",
    "def Plot(train_value, test_value, value_is_loss_or_acc):\n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot([None] + train_value, 'o-')\n",
    "    ax.plot([None] + test_value, 'x-')\n",
    "    ax.legend(['Train ' + value_is_loss_or_acc, 'Validation ' + value_is_loss_or_acc], loc = 0) \n",
    "    ax.set_title('Training/Validation ' + value_is_loss_or_acc + ' per Epoch')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(value_is_loss_or_acc)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_items2.drop([\"pid\"], axis = 1)\n",
    "X.columns = [i for i in range(X.shape[1])]\n",
    "X1 = np.array(X)\n",
    "\n",
    "nb_epoch = 200\n",
    "df_items3, his = auto(X1, 185)\n",
    "df_items3[\"pid\"] = df_items2.pid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df[\"number\"] = df[\"revenue\"] / df[\"price\"]\n",
    "    df[\"dif\"] = df[\"price\"] - df[\"competitorPrice\"]\n",
    "    \n",
    "    click = df[(df.click == 1)]\n",
    "    basket = df[(df.basket == 1)]\n",
    "    order = df[(df.order == 1)]\n",
    "    click[\"class_label\"] = 0\n",
    "    basket[\"class_label\"] = 0\n",
    "    order[\"class_label\"] = 1\n",
    "    df1 = pd.concat([click, basket, order])\n",
    "    \n",
    "    ad, ad_dim = onehot2(df.adFlag)\n",
    "    av, av_dim = onehot2(df.availability)\n",
    "    df2 = pd.concat([df1, pd.DataFrame(ad), pd.DataFrame(av)], axis=1, join_axes=[df1.index])\n",
    "    df3 = df2.drop([\"adFlag\", \"availability\"], axis=1)\n",
    "    df3 = df3.sort([\"lineID\"], ascending=True)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train0 = pd.read_csv(\"DATA/DMC_2017_task/train.csv\", sep = \"|\")\n",
    "df_train = preprocessing(df_train0)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inner(df, df_item, trainingday):\n",
    "    df = df.sort_values(['lineID', \"pid\"], ascending=True)\n",
    "    df1 = df[(df.day < trainingday)]\n",
    "    df_inner = pd.merge(df1, df_item, how='inner', on=['pid']) #df_items\n",
    "    df_inner = df_inner.sort_values(['lineID', \"pid\"], ascending=True)\n",
    "    print(df_inner.shape)\n",
    "    return df_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result0 = inner(df_train, df_item3, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################### hold on last month\n",
    "hold_result = result0[result0.day > 65]\n",
    "hold_result = hold_result.dropna()\n",
    "hold_result = hold_result.reset_index(drop = True)\n",
    "\n",
    "result = result0[result0.day <= 65]\n",
    "result = result.dropna()\n",
    "result = result.reset_index(drop = True)\n",
    "\n",
    "print('Number of hold_result: %d' % hold_result.shape[0])\n",
    "print('Number of result training: %d' % result.shape[0])\n",
    "print(result['class_label'].value_counts())\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def std(df):\n",
    "    df1 = df.drop([\"lineID\", \"number\", \"click\", \"basket\", \"order\", \"revenue\"], axis=1)\n",
    "    \n",
    "    ################################################ standardized to (0,1)\n",
    "    df_num = df[column_conti]\n",
    "    sc = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "    Z = pd.DataFrame(sc.fit_transform(df_num))\n",
    "    Z.columns = column_conti\n",
    "    ################################################ reset row index\n",
    "    df_cat = df1.drop(column_conti, axis=1)\n",
    "    df_cat = df_cat.reset_index(drop=True, inplace=False, col_level=0, col_fill='')\n",
    "    \n",
    "    df_std = df_cat.join(Z, on=None, how='inner', lsuffix='', rsuffix='', sort=False)\n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_conti = [\"day\", \"pid\", \"competitorPrice\", \"price\", \"dif\"]\n",
    "\n",
    "df_st = std(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    X = np.array(df.drop([\"class_label\"], axis=1))\n",
    "    y = np_utils.to_categorical(np.array(df[[\"class_label\"]]), 2)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    print('Number of Features: %d' % X_train.shape[1])\n",
    "    print('Number of training: %d' % X_train.shape[0])\n",
    "    print('Number of testing: %d' % X_test.shape[0])\n",
    "    a = pd.DataFrame(y_test)\n",
    "    a.columns = [\"a\", \"b\"]\n",
    "    print(\"===testing dataset label===\")\n",
    "    print(a['a'].value_counts())\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(df_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "nb_epoch = 200\n",
    "\n",
    "img_rows, img_cols = 11, 18\n",
    "nb_filters = 32\n",
    "pool_size = (2, 2)\n",
    "kernel_size = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters,\n",
    "                        kernel_size[0],\n",
    "                        kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          nb_epoch = nb_epoch,\n",
    "          verbose = 1,\n",
    "          validation_data = (X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
